services:
  kafka:
    image: apache/kafka:3.7.0
    container_name: solar_kafka
    ports:
      - "9092:9092"
    environment:
      # Configuraci√≥n KRaft para imagen oficial Apache
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      # Ajustes para entorno local (un solo nodo)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - solar_network
  # Servicio para importar datos de Solarman y enviarlos a Kafka
  import_solarman_data:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: import_solarman_data
    depends_on:
      - kafka
    environment:
      - CLIENT_ID_SOLARMAN=${CLIENT_ID_SOLARMAN}
      - CLIENT_SECRET_SOLARMAN=${CLIENT_SECRET_SOLARMAN}
      - EMAIL_SOLARMAN=${EMAIL_SOLARMAN}
      - PASSWORD_SOLARMAN=${PASSWORD_SOLARMAN}
      - PYTHONUNBUFFERED=1  # <--- ¬°A√±ade esto!      
    networks:
      - solar_network
  # Servicio ETL para mover datos de Kafka a MongoDB
  etl_to_mongo:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: etl_to_mongo
    command: python src/etl_to_mongo.py
    depends_on:
      - kafka
      - mongo
    environment:
      - PYTHONUNBUFFERED=1  # <--- ¬°Esta es la l√≠nea m√°gica! ü™Ñ
      - MONGO_USER=${MONGO_USER}
      - MONGO_PASSWORD=${MONGO_PASSWORD}
      - MONGO_HOST=mongo
      - MONGO_PORT=27017
    networks:
      - solar_network

  # Servicio de base de datos MongoDB
  mongo:
    image: mongo:latest
    container_name: solar_mongo
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    volumes:
      - mongo_data:/data/db
    networks:
      - solar_network
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      # Instalamos el plugin de comunidad para MongoDB al arrancar
      - GF_INSTALL_PLUGINS=grafana-mongodb-datasource
      # Usuario y contrase√±a por defecto (c√°mbialo si expones esto a internet)
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      # Esto guarda tus paneles para que no se borren al reiniciar
      - grafana_data:/var/lib/grafana
    depends_on:
      - mongo
    networks:
      - solar_network  # Aseg√∫rate de usar el mismo nombre de red que los otros servicios
  etl_to_influx:
    build: 
      context: .
      dockerfile: Dockerfile
    command: ["python", "src/etl_to_influx.py"]
    depends_on:
      - kafka
      - influxdb
    environment:
      - INFLUX_TOKEN=${INFLUX_TOKEN}
      - INFLUX_ORG=${INFLUX_ORG}
      - INFLUX_BUCKET=${INFLUX_BUCKET}
    networks:
      - solar_network
      
  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUX_USER}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUX_PASS}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUX_ORG}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUX_BUCKET}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUX_TOKEN}
    volumes:
      - influxdb_data:/var/lib/influxdb2
    networks:
      - solar_network
  # 1. El esp√≠a que saca datos de Kafka
  kafka-exporter:
    image: danielqsj/kafka-exporter
    container_name: kafka-exporter
    command: ["--kafka.server=kafka:9092"]
    ports:
      - "9308:9308"
    depends_on:
      - kafka
    networks:
      - solar_network

  # 2. La base de datos de m√©tricas
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - solar_network
  
  # Orquestador N8n
  n8n:
    build:
      context: .
      dockerfile: Dockerfile.n8n
    #image: n8nio/n8n
    container_name: n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${GRAFANA_USER}
      - N8N_BASIC_AUTH_PASSWORD=${GRAFANA_PASSWORD}
      - DATABRICKS_HOSTNAME=${DATABRICKS_HOSTNAME}
      - DATABRICKS_HTTP_PATH=${DATABRICKS_HTTP_PATH}
      - DATABRICKS_TOKEN=${DATABRICKS_TOKEN}
      # REUTILIZAMOS MONGO PARA EL SCRIPT:
      - MONGO_USER=${MONGO_USER}
      - MONGO_PASSWORD=${MONGO_PASSWORD}
    volumes:
      - n8n_data:/home/node/.n8n
      # Importante: Le damos acceso a tus scripts de python
      - .:/home/node/app
    networks:
      - solar_network

volumes:
  kafka_data:
    driver: local
  mongo_data:
    driver: local
  grafana_data:

  n8n_data:

  influxdb_data:

networks:
  solar_network:
    driver: bridge
